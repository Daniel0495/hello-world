hidro_pureza<- lm(hidrocarburos ~ pureza)
hidro_pureza
abline(hidro_pureza, col ="blue", lwd=2)
summary(pureza_hidro)
pureza <- c(86.91, 89.85, 90.28, 86.34, 92.58, 87.33, 86.29, 91.86, 95.61, 89.86, 96.73, 99.42, 98.66, 96.07, 93.65, 87.31, 95.00, 96.85, 85.20, 90.56)
hidrocarburos <- c(1.02, 1.11, 1.43, 1.11, 1.01, 0.95, 1.11, 0.87, 1.43, 1.02, 1.46, 1.55, 1.55, 1.55, 1.40, 1.15, 1.01, 0.99, 0.95, 0.98)
plot(hidrocarburos, pureza , ylab="pureza", pch=16, xlab="hidrocarburos", main = "diagrama de dispersión")
pureza_hidro <- lm(pureza ~ hidrocarburos)
pureza_hidro
abline(pureza_hidro, col ="red", lwd=2)
summary(pureza_hidro)
# Para hallar la correlación lineal
cor(precio, demanda)
# Para hallar la correlación lineal
cor(hidrocarburos, pureza)
cor(hidrocarburos, pureza)^2
prediccion <- predict(pureza_hidro, interval = c("prediction"))
confianza <- predict(pureza_hidro, interval = c("confidence"))
prediccion
confianza
temperatura <- c(21, 24, 32, 47, 50, 59, 68, 74, 62, 50, 41, 30)
libras_vapor <- c(185.79, 214.47, 288.03, 424.84, 454.68, 539.03, 621.55, 675.06, 562.03, 452.93, 369.95, 273.98)
plot(temperatura, libras_vapor ,xlab="temperatura", pch=16, ylab="libras_vapor", main = "diagrama de dispersion")
libras_temp <- lm(libras_vapor ~ temperatura)
libras_temp
abline(libras_temp, col ="red", lwd=2)
summary(libras_temp)
precio <- c(20, 19, 18, 18, 15, 14, 12, 11, 10, 9)
demanda <- c(5, 7, 8, 10, 11, 13, 14, 15, 17, 20)
demanda_precio <- lm(demanda ~ precio)
summary(demanda_precio)
qqnorm(demanda_precio$residuals)
qqline(demanda_precio$residuals)
shapiro.test(demanda_precio$residuals)
?lwd
??lwd
#ejemplo del libro con 3 parametros
y <- c(16.68, 11.50, 12.03, 14.88, 13.75, 18.11, 8.00, 17.83, 79.24, 21.50, 40.33, 21.00, 13.50, 19.75, 24.00, 29.00, 15.35, 19.00, 9.50, 35.10, 17.90, 52.32, 18.75, 19.83, 10.75)
x1 <- c(7, 3, 3, 4, 6, 7, 2, 7, 30, 5, 16, 10, 4, 6, 9, 10, 6, 7, 3, 17, 10, 26, 9, 8, 4)
x2 <- c(560, 220, 340, 80, 150, 330, 110, 210, 1460, 605, 688, 215, 255, 462, 448, 776, 200, 132, 36, 770, 140, 810, 450, 635, 150 )
modelo <- lm(y~x1+x2)
modelo
modelo$residuals #muestra todos lo residuos del modelo
#ejemplo del libro con 3 parametros
y <- c(16.68, 11.50, 12.03, 14.88, 13.75, 18.11, 8.00, 17.83, 79.24, 21.50, 40.33, 21.00, 13.50, 19.75, 24.00, 29.00, 15.35, 19.00, 9.50, 35.10, 17.90, 52.32, 18.75, 19.83, 10.75)
x1 <- c(7, 3, 3, 4, 6, 7, 2, 7, 30, 5, 16, 10, 4, 6, 9, 10, 6, 7, 3, 17, 10, 26, 9, 8, 4)
x2 <- c(560, 220, 340, 80, 150, 330, 110, 210, 1460, 605, 688, 215, 255, 462, 448, 776, 200, 132, 36, 770, 140, 810, 450, 635, 150 )
modelo <- lm(y~x1+x2)
modelo
modelo$residuals #muestra todos lo residuos del modelo
ygorro <- 2.34123+1.61591*x1+0.01438*x2
SSres = sum((y - ygorro)^2)
SSres
precio <- c(20, 19, 18, 18, 15, 14, 12, 11, 10, 9)
kilom <- c(5, 7, 8, 10, 11, 13, 14, 15, 17, 20)
transmisión <- c(a,m,a,m,a,m,a,m,a,m)
transmisión <- c(1,0,1,0,1,0,1,0,1,0)
plot(kilometros, transmisión, precio)
kilometros <- c(5, 7, 8, 10, 11, 13, 14, 15, 17, 20)
transmisión <- c(1,0,1,0,1,0,1,0,1,0)   #donde 1 es automática, y 0 manual
plot(kilometros, transmisión, precio)
contour(kilometros, transmisión, precio)
plot(kilometros, precio)
#ejemplo del libro con 3 parametros
y <- c(16.68, 11.50, 12.03, 14.88, 13.75, 18.11, 8.00, 17.83, 79.24, 21.50, 40.33, 21.00, 13.50, 19.75, 24.00, 29.00, 15.35, 19.00, 9.50, 35.10, 17.90, 52.32, 18.75, 19.83, 10.75)
x1 <- c(7, 3, 3, 4, 6, 7, 2, 7, 30, 5, 16, 10, 4, 6, 9, 10, 6, 7, 3, 17, 10, 26, 9, 8, 4)
x2 <- c(560, 220, 340, 80, 150, 330, 110, 210, 1460, 605, 688, 215, 255, 462, 448, 776, 200, 132, 36, 770, 140, 810, 450, 635, 150 )
modelo <- lm(y~x1+x2)
modelo
modelo$residuals #muestra todos lo residuos del modelo
ygorro <- 2.34123+1.61591*x1+0.01438*x2
ygorro
summary(modelo)
sumayi1 <- sum(y^2) #forma 1 haciendo cada yi al cuadrado
sumayi2 <- t(y)%*%y #forma 2 haciendo producto de vectores
SSres = sum((y - ygorro)^2)
SSres
contour(x1, x2, y)
persp(x1, x2, y)
modelo <- lm(precio~kilometros + transmisión)
modelo
modelo2 <- lm(precio[transmisión==1]~kilometros[transmisión==1])
modelo2
modelo
25.333-0.9128
summary(modelo)
summary(modelo2)
plot(kilometros, precio)
abline(modelo)
plot(kilometros, precio)
abline(modelo2)
model <- lm(p~k)
p <- c(20, 18, 15, 12, 10)
k <- c(5, 8, 11, 14, 17)
model <- lm(p~k)
model
modelo2
precio <- c(20, 19, 18, 18, 15, 14, 12, 11, 10, 9) #en miles de millones
kilometros <- c(5, 7, 8, 10, 11, 13, 14, 15, 17, 20) #en miles de kilo
transmisión <- c(1,0,1,0,1,0,1,0,1,0)   #donde 1 es automática, y 0 mecánica
modelo <- lm(precio~kilometros + transmisión)
plot(modelo)
pureza <- c(86.91, 89.85, 90.28, 86.34, 92.58, 87.33, 86.29, 91.86, 95.61, 89.86, 96.73, 99.42, 98.66, 96.07, 93.65, 87.31, 95.00, 96.85, 85.20, 90.56)
hidrocarburos <- c(1.02, 1.11, 1.43, 1.11, 1.01, 0.95, 1.11, 0.87, 1.43, 1.02, 1.46, 1.55, 1.55, 1.55, 1.40, 1.15, 1.01, 0.99, 0.95, 0.98)
plot(hidrocarburos, pureza , ylab="pureza", pch=16, xlab="hidrocarburos", main = "diagrama de dispersiÃ³n")
pureza_hidro <- lm(pureza ~ hidrocarburos)
pureza_hidro
abline(pureza_hidro, col ="red", lwd=2)
plot(kilometros, precio)
abline(modelo)
modelo
library(readr)
bdapartamentos <- read_csv("bdapartamentos.csv")
View(bdapartamentos)
library(readxl)
bdapartamentos1 <- read_excel("bdapartamentos1.xlsx",
col_types = c("text", "text", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "text", "text", "numeric",
"numeric", "text", "text", "text"))
View(bdapartamentos1)
# Para leer la base de datos desde excel
datos <- read.csv2(file.choose(), header=T, sep = ";")
plot(datos)
precio <- datos$precio.por.metro.millones
estrato <- as.character(datos$Estrato)
baños <- datos$banos
area <- datos$area
hab <- datos$habitaciones
parq <- datos$parqueadero
admonxm2 <- datos$Admon.por.mt.2
admon <- datos$Admón
# Verifiquemos si la variable respuesta tiene dist normal
hist(precio)
summary(precio)
plot(density(precio))
shapiro.test(precio)
boxplot(precio, horizontal = T)
#para calcular una correlación lineal. Se hace el gráfico
#para tener intuición
plot(area, hab)
cov(area, hab)/(sd(area)*sd(hab))
# Para calcular la matriz de correlaciones entre un subgrupo
# de columnas de la base de datos
cor(datos[,1:8])
# Para calcular la matriz de correlaciones entre un subgrupo
# de columnas de la base de datos
cor(datos[,1:8])
x
# Para calcular la matriz de correlaciones entre un subgrupo
# de columnas de la base de datos
cor(datos[,1:3])
datos
modelo1 <- lm(precio~estrato+area+hab)
summary(modelo1)
anova(modelo1)
plot(modelo1)
plot(datos)
shapiro.test(modelo1$residuals)
summary(modelo1)
anova(modelo1)
model.matrix(modelo1)
anova(modelo1)
estrato
sum(estrato)
area
sum(area)
sum(area-mean(area))
sum((area-mean(area))^2)
anova(modelo1)
precio <- c(20, 19, 18, 18, 15, 14, 12, 11, 10, 9) #en miles de millones
kilometros <- c(5, 7, 8, 10, 11, 13, 14, 15, 17, 20) #en miles de kilo
transmisión <- c(1,0,1,0,1,0,1,0,1,0)   #donde 1 es automática, y 0 mecánica
modelo <- lm(precio~kilometros + transmisión)
summary(modelo)
qt(7,0.957)
qt(3,7,0.957)
qt(7,0.025)
qt(3,7,0.05)
qt(0.025, 7)
qt(0.975, 7)
summary(modelo)
qt(0.975, 7)
anova(modelo)
qf(0.025, 2,7)
# EJERCICIO. Ajustar un modelo con interacciÃÂ³n entre regresoras. Los datos son:
x1 <- c(1, 1, -1, -1, 0, 0, 0, 0, 0, 1.5, -1.5)
x2 <- c(-1, 1, 1, -1, 0, 0, 0, 1.5, -1.5, 0, 0)
w <- c(83, 113, 92, 82, 100, 96, 98, 95, 80, 100, 92)
x1x2 <- x1*x2
x22 <- x2*x2
x11 <- x1*x1
modelo2 <- lm(w~x1+x2+x1x2+x22+x11)
modelo1 <- lm(w~ x1+x2)
summary(modelo1)
summary(modelo2)
f <- (ssres0 - ssres)/(ssres*3)
ssres0 <- ((6.39)^2) * 5
ssres <- ((3.948)^2) * 5
f <- (ssres0 - ssres)/(ssres*3)
f
qf(0.95,3,5)
qf(0.025,3,5)
ssres0 <- ((6.39)^2) * 3
ssres <- ((3.948)^2) * 5
f <- ((ssres0 - ssres)*5)/(ssres*3)
qf(0.025,3,5)
f
qf(0.975,3,5)
summary(modelo1)
modelo2 <- lm(w~x1+x2+x1x2+x22+x11)
modelo1 <- lm(w~ x1+x2)
modelo3 <- lm(w~ x1+x2+x22)
modelo4 <- lm(w~ x1+x2+x22+ x1x2)
modelo1
modelo2
modelo3
modelo4
modelo <- lm(precio~kilometros + transmisión)
modelo
modelo2 <- lm(precio[transmisión==1]~kilometros[transmisión==1])
modelo2
modelo3<- lm(precio~kilometros)
modelo3
modelo
# EJERCICIO. Ajustar un modelo con interacción entre regresoras. Los datos son:
x1 <- c(1, 1, -1, -1, 0, 0, 0, 0, 0, 1.5, -1.5)
x2 <- c(-1, 1, 1, -1, 0, 0, 0, 1.5, -1.5, 0, 0)
w <- c(83, 113, 92, 82, 100, 96, 98, 95, 80, 100, 92)
x1x2 <- x1*x2
x22 <- x2*x2
x11 <- x1*x1
shapiro.test(w)
#da un valor p = 0.5104.  La hipótesis nula es que w es normal, no se rechaza.
cor(data.frame(x1,x2))
modelo1 <- lm(w~ x1+x2)
summary(modelo1)
modelo1 <- lm(w~ x1)
summary(modelo1)
modelo2 <- lm(w~x1+x2+x1x2+x22+x11)
summary(modelo2)
modelo3 <- lm(w~x2+x1x2+x22+x11)
summary(modelo3)
cor(data.frame(x1,x2))
modelo1 <- lm(w~ x1+x2)
summary(modelo1)
modelo2 <- lm(w~x2+x1x2+x22+x11)
summary(modelo2)
modelo11 <- lm(w~x2)
modelo11 <- lm(w~x2)
modelo12 <- lm(w~x1)
anova(modelo11, modelo12)
anova(modelo11, modelo1)
modelo21 <-lm(w~x2+x22)
summary(modelo21)
summary(modelo2)
SSres1 <- ((5.971)^2)*6
SSres01 <- ((6.316)^2)*8
f1 <- ((SSres01-SSres1)*6)/(SSres1*2)
f1
qf(0.975,2,6)
qf(0.0.025,2,6)
qf(0.025,2,6)
modelo3 <- lm(w~x2+x22)
summary(modelo3)
modelo_bueno <- lm(w~x1+x2+x1x2+x22)
modelo_bueno
summary(modelo_bueno)
modelo_intento <- lm(w~x1+x2+x1x2+x22+x11)
summary(modelo_intento)
modelo1 <- lm(w~x1+x2)
summary(modelo1)
anova(modelo21,modelo2)
sum(modelo3$residuals)
sum(modelo_bueno$residuals)
sum(modelo3$residuals)-sum(modelo_bueno$residuals)
sum(modelo_bueno$residuals)-sum(modelo3$residuals)
sum(modelo3$residuals^2)-sum(modelo_bueno$residuals^2)
sum(modelo3$residuals^2)
sum(modelo_bueno$residuals^2)
anova(modelo11, modelo1)
# Nos quedamos solo con x2, pero analizamos aportes cuadráticos y conjunto:
#_____________________________
modelo2 <- lm(w~x2+x1x2+x22+x11)
summary(modelo2)
modelo_intento <- lm(w~x1+x2+x1x2+x22+x11)
summary(modelo_intento)
#crear matrices
z<- matrix(c(1,2,3,4,5,6,7,8,9),3,3)
z
#crear matrices
z<- matrix(c(1,2,3,4,5,6),2,3)
z
#crear matrices
z<- matrix(c(1,2,3;4,5,6))
z
#crear matrices
z<- matrix(c(1,2,3;4,5,6))
z
#crear matrices
z<- matrix(c(1,2,3);c(4,5,6))
z
#crear matrices
z<- matrix(c(1,2,3);c(4,5,6))
z
#crear matrices
z<- matrix(c(1,2,3),c(4,5,6))
z
#crear matrices
z<- matrix(c(1,2,3,4,5,6))
z
#crear matrices
z<- matrix(c(1,2,3,4,5,6),3,2)
source('~/.active-rstudio-document', echo=TRUE)
z
h<- t(z)%*%z
h
i<-matrix( c(1,0,0,1),2,2)
i
h_1<-solve(h,i)
h_1
h_1%*%h
h%*%h_1
I<-diag(rep(1;50))
I<-diag(rep(1,50))
I
rep(1,50)
I<-diag(c(rep(1,50)))
rep(1,50)
I
I<-diag(c(rep(1,10)))
I
solve(h)
h_1<-solve(h,i)
h_1
library(readxl)
ejercicio37 <- read_excel("ejercicio37.xlsx",
col_types = c("numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"text"))
View(ejercicio37)
library(readxl)
ejercicio37 <- read_excel("ejercicio37.xlsx",
col_types = c("numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"text", "numeric"))
View(ejercicio37)
#leer datos: file/importar dataset
y <- ejercicio37$y
#leer datos: file/importar dataset
y <- ejercicio37$y
x1 <- ejercicio37$desplamiento
x2 <- ejercicio37$cabafuerza
x3<- ejercicio37$torque
x4 <- ejercicio37$carburador
x5 <- ejercicio37$cambios
x6 <- ejercicio37$lg
x7 <- ejercicio37$ancho
x8 <- ejercicio37$peso
x9 <- ejercicio37$tipotra
#comprobamos la normalidad de la y
shapiro.test(y)
#leer datos: file/importar dataset
y <- ejercicio37$y
qqnorm(y)
qqplot
qqplot(y)
qqnorm(y)
qqplot
qqline(y)
histogram(y)
hist(y)
raizy <- c()
for (i in 1:length(y)) {
raizy[i] <- sqrt(y[i])
}
shapiro.test(raizy)
raizy <- c()
for (i in 1:length(y)) {
raizy[i] <- log(y[i])
}
shapiro.test(raizy)
hist(w)
qqnorm(w)
qqline(w)
#Modelo de regresión lineal múltiple para w
modelo_completo <- lm(w~x1+x2+x3+x4+x5+x6+x7+x8+x9)
#leer datos: file/importar dataset
y <- ejercicio37$y
x1 <- ejercicio37$desplamiento
x2 <- ejercicio37$cabafuerza
x4 <- ejercicio37$carburador
x3<- ejercicio37$torque
x5 <- ejercicio37$cambios
x6 <- ejercicio37$lg
x7 <- ejercicio37$ancho
x8 <- ejercicio37$peso
x9 <- ejercicio37$tipotra
logy <- c()
for (i in 1:length(y)) {
logy[i] <- log(y[i])
}
shapiro.test(logy)
hist(logy)
qqnorm(logy)
qqline(logy)
#Modelo de regresión lineal múltiple para w
modelo_completo <- lm(logy~x1+x2+x3+x4+x5+x6+x7+x8+x9)
logy
logy <- log(y)
modelo_completo
summary(modelo_completo)
qf(0.025, 9, 22)
qf(0.975, 9, 22)
#el resumen del modelo dice que el modelo es significativo. Analizamos las
#correlaciones
datos <- data.frame(x1,x2,x3,x4,x5,x6,x7,x8,x9)
cor(datos)
#el resumen del modelo dice que el modelo es significativo. Analizamos las
#correlaciones
datos <- data.frame(x1,x2,x3,x4,x5,x6,x7,x8)
cor(datos)
datos <- data.frame(x1,x2,x3,x4,x5,x6,x7,x8)
cor(datos)
intall.packages("MVP")
install.packages("MVP")
install.packages("mvp")
library("mvp", lib.loc="~/R/win-library/3.5")
data(table.B1)
data(table.b1)
data(table.b.1)
data(tableb1)
is.mvp(table.b1)
is.mvp(tableb1)
library("MVP")
intall.packages("MVP")
install.packages("MVP")
intall.packages("MPV")
intall.packages("MPV")
install.packages("MPV")
library("MPV")
data("table.b1")
datos <- data("table.b1")
datos
data("table.b4")
table.b4
y <- table.b4$y
x1 <- table.b4$x1
x2 <- table.b4$x2
x3 <- table.b4$x3
x4 <- table.b4$x4
x5 <- table.b4$x5
x6 <- table.b4$x6
x7 <- table.b4$x7
x8 <- table.b4$x8
x9 <- table.b4$x9
# normalidad de y:
shapiro.test(y)
table.b3
#modelo general:
modelog <- lm(y~ x1+x2+x3+x4+x5+x6+x7+x8+x9)
summary(modelog)
cor(data.frame(x1,x2,x3,x4,x5,x6,x7,x8,x9))
#___________________________________
#modelo sin x6
modelo_6 <- lm(y~ x1+x2+x3+x4+x5+x7+x8+x9)
summary(modelo_6)
#modelo es significativo, x1 ya es aportante. x3 sigue siendo la más insignificante
cor(data.frame(x1,x2,x3,x4,x5,x7,x8,x9))
#_________________________________________
#modelo sin x6 y sin x3
modelo_63 <- lm(y~ x1+x2+x4+x5+x7+x8+x9)
summary(modelo_63)
#_____________________________
#modelo sin x6, x3 y x8
modelo_638 <- lm(y~ x1+x2+x4+x5+x7+x9)
summary(modelo_638)
cor(data.frame(x1,x2,x4,x5,x7,x8,x9))
#_____________________________
#modelo sin x6, x3 y x4
modelo_634 <- lm(y~ x1+x2+x8+x5+x7+x9)
summary(modelo_634)
summary(modelo_638)
anova(modelo_634, modelo_638)
modelo_6384 <- lm(y~ x1+x2+x5+x7+x9)
anova(modelo_6384, modelo_634)
#por la prueba del anova encontramos que el x8 no es significativo, al eliminar el x4
# vimos significancia de x2
modelo_6384 <- lm(y~ x1+x2+x5+x7+x9)
summary(modelo_6384)
plot(y)
hist(y)
qqplot(y)
qqnorm(y)
qqline
qqline(y)
cor(data.frame(x1,x2,x5,x7,x9))
summary(modelo_6384)
cor(data.frame(x1,x2,x5,x7,x9))
summary(modelog)
summary(modelo_6)
summary(modelo_63)
summary(modelo_634)
summary(modelo_638)
summary(modelo_6384)
cor(data.frame(x1,x2,x5,x7,x9))
pairs(y~x1,x2,x5,x7.x9)
pairs(y~x1,x2,x5,x7,x9)
pairs(y~x1+x2+x5+x7+x9)
